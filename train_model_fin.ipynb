{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90500f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GN\\anaconda3\\envs\\computer_vision\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# --- 1. CONFIG ---\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 30\n",
    "IMG_SIZE = 64\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- 2. DATA LOADING ---\n",
    "print(\"Downloading Dataset...\")\n",
    "DATASET_PATH = kagglehub.dataset_download(\"prasadvpatil/mrl-dataset/versions/3\")\n",
    "TRAIN_DIR = os.path.join(DATASET_PATH, \"train\")\n",
    "\n",
    "classes = sorted(os.listdir(TRAIN_DIR)) # [\"Closed_Eyes\", \"Open_Eyes\"]\n",
    "all_paths, all_labels, all_subjects = [], [], []\n",
    "\n",
    "for label_idx, label in enumerate(classes):\n",
    "    class_dir = os.path.join(TRAIN_DIR, label)\n",
    "    for img_file in os.listdir(class_dir):\n",
    "        if img_file.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            all_paths.append(os.path.join(class_dir, img_file))\n",
    "            all_labels.append(label_idx)\n",
    "            # Extract Subject ID (e.g. s0001 from s0001_00234...)\n",
    "            all_subjects.append(os.path.basename(img_file).split('_')[0])\n",
    "\n",
    "df = pd.DataFrame({'path': all_paths, 'label': all_labels, 'subject': all_subjects})\n",
    "\n",
    "# --- 3. SPLITTING (The Correct Way) ---\n",
    "# Step A: Split off 10% for the TEST VAULT (Never touch during training)\n",
    "splitter_test = GroupShuffleSplit(test_size=0.1, n_splits=1, random_state=42)\n",
    "train_val_idx, test_idx = next(splitter_test.split(df, groups=df['subject']))\n",
    "\n",
    "train_val_df = df.iloc[train_val_idx]\n",
    "test_df = df.iloc[test_idx]\n",
    "\n",
    "# Step B: Split the remaining 90% into TRAIN (80%) and VAL (10%)\n",
    "# 0.11 of the remaining 90% is approx 10% of the total\n",
    "splitter_val = GroupShuffleSplit(test_size=0.11, n_splits=1, random_state=42)\n",
    "train_idx, val_idx = next(splitter_val.split(train_val_df, groups=train_val_df['subject']))\n",
    "\n",
    "train_df = train_val_df.iloc[train_idx]\n",
    "val_df = train_val_df.iloc[val_idx]\n",
    "\n",
    "print(f\"Train Subjects: {train_df['subject'].nunique()} ({len(train_df)} images)\")\n",
    "print(f\"Val Subjects:   {val_df['subject'].nunique()} ({len(val_df)} images)\")\n",
    "print(f\"Test Subjects:  {test_df['subject'].nunique()} ({len(test_df)} images) <- HIDDEN VAULT\")\n",
    "\n",
    "# --- 4. DATASET CLASS ---\n",
    "class EyeDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row['path']).convert(\"L\") # Grayscale\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, row['label']\n",
    "\n",
    "# Transforms\n",
    "train_tfm = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "eval_tfm = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Loaders\n",
    "train_ds = EyeDataset(train_df, train_tfm)\n",
    "val_ds = EyeDataset(val_df, eval_tfm)\n",
    "test_ds = EyeDataset(test_df, eval_tfm)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "# --- 5. MODEL (Custom CNN) ---\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            # Block 2\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            # Block 3\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(), nn.MaxPool2d(2),\n",
    "            # Head\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128 * (IMG_SIZE//8) * (IMG_SIZE//8), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "model = CNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "\n",
    "# --- 6. TRAINING ---\n",
    "best_acc = 0.0\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for imgs, lbls in train_loader:\n",
    "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(imgs)\n",
    "        loss = criterion(out, lbls)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in val_loader:\n",
    "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "            out = model(imgs)\n",
    "            _, pred = torch.max(out, 1)\n",
    "            correct += (pred == lbls).sum().item()\n",
    "            total += lbls.size(0)\n",
    "    \n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}: Loss {total_loss/len(train_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    scheduler.step(total_loss)\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_eye_model.pth\")\n",
    "\n",
    "print(\"Training Done.\")\n",
    "\n",
    "# --- 7. FINAL TEST (The Truth) ---\n",
    "print(\"\\n--- FINAL TEST SET EVALUATION ---\")\n",
    "model.load_state_dict(torch.load(\"best_eye_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, lbls in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        out = model(imgs)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        y_true.extend(lbls.numpy())\n",
    "        y_pred.extend(pred.cpu().numpy())\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=classes))\n",
    "\n",
    "# Save for Export\n",
    "torch.save(model.state_dict(), \"final_model_weights.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
